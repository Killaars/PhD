{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kendalltau\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "knmipath = '/nobackup/users/killaars/PhD_data/test'\n",
    "\n",
    "flask_in = os.path.join(knmipath,'sample_coordinates_2007111000_2007111700.nc')\n",
    "flask_mp = os.path.join(knmipath,'flask_output_TM5_MP_2007111000_2007111700.nc')\n",
    "flask_esm = os.path.join(knmipath,'flask_output_ECE_2007111000_2007111700.nc')\n",
    "\n",
    "flask_in_fh = nc.Dataset(flask_in,mode='r')\n",
    "flask_mp_fh = nc.Dataset(flask_mp,mode='r')\n",
    "flask_esm_fh = nc.Dataset(flask_esm,mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((25427,), (25427,), (25427,))\n",
      "(25427,)\n"
     ]
    }
   ],
   "source": [
    "x = 40000000\n",
    "fin_obs = flask_in_fh.variables['observed'][:x]\n",
    "fin_date = flask_in_fh.variables['date_components'][:x]\n",
    "obs_num = flask_in_fh.variables['obs_num'][:x]\n",
    "lat = flask_in_fh.variables['latitude'][:x]\n",
    "lon = flask_in_fh.variables['longitude'][:x]\n",
    "alt = flask_in_fh.variables['altitude'][:x]\n",
    "fmp_obs0 = flask_mp_fh.variables['flask'][:x,0] #Are 10 members. First check if it works with 1\n",
    "fesm_obs = flask_esm_fh.variables['flask'][:x,0]\n",
    "\n",
    "#check if the shapes are similar, meaning that they have the same number of points\n",
    "print(np.shape(fin_obs),np.shape(fmp_obs0),np.shape(fesm_obs))\n",
    "\n",
    "#Code to transform the date components of the input file to a pandas series of timestamps\n",
    "N = (len(fin_obs))\n",
    "base = datetime.datetime(1900, 1, 1)\n",
    "time = np.array([base + datetime.timedelta(hours=i) for i in xrange(N)])\n",
    "for i in range(N):\n",
    "    dt = datetime.datetime(fin_date[i,0],fin_date[i,1],fin_date[i,2],fin_date[i,3],fin_date[i,4],fin_date[i,5])\n",
    "    time[i] = pd.Timestamp(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A_fin_obs' : fin_obs,\n",
    "                   'B_fmp_obs' : fmp_obs0,\n",
    "                   'C_fesm_obs': fesm_obs,\n",
    "                   'D_alt'     : alt,\n",
    "                   'E_lat'     : lat,\n",
    "                   'F_lon'     : lon,\n",
    "                   'G_date'    : time},index=obs_num)\n",
    "\n",
    "\n",
    "PAL = (df.E_lat>67) & (df.E_lat<68) & (df.F_lon>24) & (df.F_lon<25) #PALLAS in Finland\n",
    "CBW = (df.E_lat>51) & (df.E_lat<52) & (df.F_lon>4) & (df.F_lon<5) #Cabauw in the Netherlands\n",
    "LEF = (df.E_lat>45) & (df.E_lat<46) & (df.F_lon>-91) & (df.F_lon<-90) #Park Falls in Wisconsin (USA)\n",
    "JFJ = (df.E_lat>46) & (df.E_lat<47) & (df.F_lon>7) & (df.F_lon<8) #Jungfraujoch in Switserland\n",
    "#df[JFJ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "mask = JFJ\n",
    "ax.plot_date(x=df.G_date[mask], y=df.A_fin_obs[mask], color='g', alpha=.2, label='Observations')\n",
    "ax.plot_date(x=df.G_date[mask], y=df.B_fmp_obs[mask], color='b', alpha=.2, label='TM5-Offline')\n",
    "ax.plot_date(x=df.G_date[mask], y=df.C_fesm_obs[mask], color='r', alpha=.2, label='TM5-ESM')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {'date': ['2014-05-01 18:47:05.069722', '2014-05-01 18:47:05.119994', '2014-05-02 18:47:05.178768', '2014-05-02 18:47:05.230071', '2014-05-02 18:47:05.230071', '2014-05-02 18:47:05.280592', '2014-05-03 18:47:05.332662', '2014-05-03 18:47:05.385109', '2014-05-04 18:47:05.436523', '2014-05-04 18:47:05.486877'],\n",
    "        'deaths_regiment_1': [34, 43, 14, 15, 15, 14, 31, 25, 62, 41],\n",
    "        'deaths_regiment_2': [52, 66, 78, 15, 15, 5, 25, 25, 86, 1],\n",
    "        'deaths_regiment_3': [13, 73, 82, 58, 52, 87, 26, 5, 56, 75],\n",
    "        'deaths_regiment_4': [44, 75, 26, 15, 15, 14, 54, 25, 24, 72],\n",
    "        'deaths_regiment_5': [25, 24, 25, 15, 57, 68, 21, 27, 62, 5],\n",
    "        'deaths_regiment_6': [84, 84, 26, 15, 15, 14, 26, 25, 62, 24],\n",
    "        'deaths_regiment_7': [46, 57, 26, 15, 15, 14, 26, 25, 62, 41]}\n",
    "df = pd.DataFrame(data, columns = ['date', 'battle_deaths', 'deaths_regiment_1', 'deaths_regiment_2',\n",
    "                                   'deaths_regiment_3', 'deaths_regiment_4', 'deaths_regiment_5',\n",
    "                                   'deaths_regiment_6', 'deaths_regiment_7'])\n",
    "df = df.set_index(df.date)\n",
    "sns.tsplot([df.deaths_regiment_1, df.deaths_regiment_2, df.deaths_regiment_3, df.deaths_regiment_4,\n",
    "            df.deaths_regiment_5, df.deaths_regiment_6, df.deaths_regiment_7], color=\"indianred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. TIME SERIES PLOT FOR SELECTED STATIONS\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "knmipath = '/nobackup/users/killaars/PhD_data/runs_may_2017/'\n",
    "macbookpath = '/Users/killaars/PhD/test/'\n",
    "path = knmipath\n",
    "\n",
    "fin_obs = []\n",
    "time = []\n",
    "obs_num = []\n",
    "lat = []\n",
    "lon = []\n",
    "alt = []\n",
    "fmp_obs0 = []\n",
    "fesm_obs = []\n",
    "for root, dirs, files in os.walk(os.path.join(path,'sample_flasks')):\n",
    "    for file in sorted(files):\n",
    "        if file.startswith('sample_coordinates_'):\n",
    "            #print(file,file[19:])\n",
    "            #print 'flask_output_TM5_MP_'+file[19:]            \n",
    "            #print 'flask_output_ECE_'+file[19:]\n",
    "            TM5_MP_filename = 'flask_output_TM5_MP_'+file[19:]\n",
    "            ECE_filename = 'flask_output_ECE_'+file[19:]\n",
    "            \n",
    "            flask_in = os.path.join(path,'sample_flasks',file)\n",
    "            flask_mp = os.path.join(path,'TM5_offline',TM5_MP_filename)\n",
    "            flask_esm = os.path.join(path,'TM5_ESM',ECE_filename)\n",
    "\n",
    "            flask_in_fh = nc.Dataset(flask_in,mode='r')\n",
    "            flask_mp_fh = nc.Dataset(flask_mp,mode='r')\n",
    "            flask_esm_fh = nc.Dataset(flask_esm,mode='r')\n",
    "            \n",
    "            x = 40000000\n",
    "            fin_obs = np.append(fin_obs,flask_in_fh.variables['observed'][:x])\n",
    "            fin_date = flask_in_fh.variables['date_components'][:x]\n",
    "            obs_num = np.append(obs_num,flask_in_fh.variables['obs_num'][:x])\n",
    "            lat = np.append(lat,flask_in_fh.variables['latitude'][:x])\n",
    "            lon = np.append(lon,flask_in_fh.variables['longitude'][:x])\n",
    "            alt = np.append(alt,flask_in_fh.variables['altitude'][:x])\n",
    "            fmp_obs0 = np.append(fmp_obs0,flask_mp_fh.variables['flask'][:x,0]) #Are 10 members. First check if it works with 1\n",
    "            fesm_obs = np.append(fesm_obs,flask_esm_fh.variables['flask'][:x,0])\n",
    "            \n",
    "            flask_in_fh.close()\n",
    "            flask_mp_fh.close()\n",
    "            flask_esm_fh.close()\n",
    "\n",
    "            #check if the shapes are similar, meaning that they have the same number of points\n",
    "            #print(np.shape(fin_obs),np.shape(fmp_obs0),np.shape(fesm_obs))\n",
    "            \n",
    "            #Code to transform the date components of the input file to a pandas series of timestamps\n",
    "            N = (len(fin_date))\n",
    "            base = datetime.datetime(1900, 1, 1)\n",
    "            time_intermediate = np.array([base + datetime.timedelta(hours=i) for i in range(N)])\n",
    "            for i in range(N):\n",
    "                dt = datetime.datetime(fin_date[i,0],fin_date[i,1],fin_date[i,2],fin_date[i,3],fin_date[i,4],fin_date[i,5])\n",
    "                time_intermediate[i] = pd.Timestamp(dt)\n",
    "            time = np.append(time,time_intermediate)    \n",
    "\n",
    "df = pd.DataFrame({'A_fin_obs' : fin_obs*1000000,\n",
    "                   'B_fmp_obs' : fmp_obs0*1000000,\n",
    "                   'C_fesm_obs': fesm_obs*1000000,\n",
    "                   'D_alt'     : alt,\n",
    "                   'E_lat'     : lat,\n",
    "                   'F_lon'     : lon,\n",
    "                   'G_date'    : time},index=obs_num)\n",
    "\n",
    "\n",
    "CBW = (df.E_lat>51) & (df.E_lat<52) & (df.F_lon>4) & (df.F_lon<5) & (df.D_alt<100) #Cabauw in the Netherlands\n",
    "PAL = (df.E_lat>67) & (df.E_lat<68) & (df.F_lon>24) & (df.F_lon<25) #PALLAS in Finland\n",
    "LEF = (df.E_lat>45) & (df.E_lat<46) & (df.F_lon>-91) & (df.F_lon<-90) #Park Falls in Wisconsin (USA)\n",
    "JFJ = (df.E_lat>46) & (df.E_lat<47) & (df.F_lon>7) & (df.F_lon<8) #Jungfraujoch in Switserland\n",
    "#print(df[JFJ])\n",
    "\n",
    "f, (ax1, ax2,ax3,ax4) = plt.subplots(4, 1, sharex=True)\n",
    "size = 2\n",
    "alpha=.3\n",
    "mask = LEF\n",
    "ax1.set_title('LEF')\n",
    "ax1.plot_date(x=df.G_date[mask], y=df.A_fin_obs[mask], color='g', alpha=alpha, ms=size, label='Observations')\n",
    "ax1.plot_date(x=df.G_date[mask], y=df.B_fmp_obs[mask], color='b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax1.plot_date(x=df.G_date[mask], y=df.C_fesm_obs[mask], color='r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "\n",
    "mask=CBW\n",
    "ax2.set_title('CBW')\n",
    "ax2.plot_date(x=df.G_date[mask], y=df.A_fin_obs[mask], color='g', alpha=alpha, ms=size, label='Observations')\n",
    "ax2.plot_date(x=df.G_date[mask], y=df.B_fmp_obs[mask], color='b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax2.plot_date(x=df.G_date[mask], y=df.C_fesm_obs[mask], color='r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "\n",
    "mask=PAL\n",
    "ax3.set_title('PAL')\n",
    "ax3.plot_date(x=df.G_date[mask], y=df.A_fin_obs[mask], color='g', alpha=alpha, ms=size, label='Observations')\n",
    "ax3.plot_date(x=df.G_date[mask], y=df.B_fmp_obs[mask], color='b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax3.plot_date(x=df.G_date[mask], y=df.C_fesm_obs[mask], color='r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "\n",
    "mask=JFJ\n",
    "ax4.set_title('JFJ')\n",
    "ax4.plot_date(x=df.G_date[mask], y=df.A_fin_obs[mask], color='g', alpha=alpha, ms=size, label='Observations')\n",
    "ax4.plot_date(x=df.G_date[mask], y=df.B_fmp_obs[mask], color='b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax4.plot_date(x=df.G_date[mask], y=df.C_fesm_obs[mask], color='r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2. TIME SERIES PLOT FOR SELECTED STATIONS with errorbars - errorbars very small due to the very similar ensemble members\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "knmipath = '/nobackup/users/killaars/PhD_data/runs_may_2017'\n",
    "macbookpath = '/Users/killaars/PhD/test/'\n",
    "path = knmipath\n",
    "\n",
    "fin_obs = []\n",
    "time = []\n",
    "obs_num = []\n",
    "lat = []\n",
    "lon = []\n",
    "alt = []\n",
    "fmp_obs0 = []\n",
    "fmp_obs1 = []\n",
    "fmp_obs2 = []\n",
    "fmp_obs3 = []\n",
    "fmp_obs4 = []\n",
    "fmp_obs5 = []\n",
    "fmp_obs6 = []\n",
    "fmp_obs7 = []\n",
    "fmp_obs8 = []\n",
    "fmp_obs9 = []\n",
    "\n",
    "fesm_obs0 = []\n",
    "fesm_obs1 = []\n",
    "fesm_obs2 = []\n",
    "fesm_obs3 = []\n",
    "fesm_obs4 = []\n",
    "fesm_obs5 = []\n",
    "fesm_obs6 = []\n",
    "fesm_obs7 = []\n",
    "fesm_obs8 = []\n",
    "fesm_obs9 = []\n",
    "for root, dirs, files in os.walk(os.path.join(path,'sample_flasks')):\n",
    "    for file in sorted(files):\n",
    "        if file.startswith('sample_coordinates_'):\n",
    "            #print(file,file[19:])\n",
    "            #print 'flask_output_TM5_MP_'+file[19:]            \n",
    "            #print 'flask_output_ECE_'+file[19:]\n",
    "            TM5_MP_filename = 'flask_output_TM5_MP_'+file[19:]\n",
    "            ECE_filename = 'flask_output_ECE_'+file[19:]\n",
    "            \n",
    "            flask_in = os.path.join(path,'sample_flasks',file)\n",
    "            flask_mp = os.path.join(path,'TM5_offline',TM5_MP_filename)\n",
    "            flask_esm = os.path.join(path,'TM5_ESM',ECE_filename)\n",
    "\n",
    "            flask_in_fh = nc.Dataset(flask_in,mode='r')\n",
    "            flask_mp_fh = nc.Dataset(flask_mp,mode='r')\n",
    "            flask_esm_fh = nc.Dataset(flask_esm,mode='r')\n",
    "            \n",
    "            x = 40000000\n",
    "            fin_obs = np.append(fin_obs,flask_in_fh.variables['observed'][:x])\n",
    "            fin_date = flask_in_fh.variables['date_components'][:x]\n",
    "            obs_num = np.append(obs_num,flask_in_fh.variables['obs_num'][:x])\n",
    "            lat = np.append(lat,flask_in_fh.variables['latitude'][:x])\n",
    "            lon = np.append(lon,flask_in_fh.variables['longitude'][:x])\n",
    "            alt = np.append(alt,flask_in_fh.variables['altitude'][:x])\n",
    "            \n",
    "            fmp_obs0 = np.append(fmp_obs0,flask_mp_fh.variables['flask'][:x,0]) #Are 10 members. First check if it works with 1\n",
    "            fmp_obs1 = np.append(fmp_obs1,flask_mp_fh.variables['flask'][:x,1])\n",
    "            fmp_obs2 = np.append(fmp_obs2,flask_mp_fh.variables['flask'][:x,2])\n",
    "            fmp_obs3 = np.append(fmp_obs3,flask_mp_fh.variables['flask'][:x,3])\n",
    "            fmp_obs4 = np.append(fmp_obs4,flask_mp_fh.variables['flask'][:x,4])\n",
    "            fmp_obs5 = np.append(fmp_obs5,flask_mp_fh.variables['flask'][:x,5])\n",
    "            fmp_obs6 = np.append(fmp_obs6,flask_mp_fh.variables['flask'][:x,6])\n",
    "            fmp_obs7 = np.append(fmp_obs7,flask_mp_fh.variables['flask'][:x,7])\n",
    "            fmp_obs8 = np.append(fmp_obs8,flask_mp_fh.variables['flask'][:x,8])\n",
    "            fmp_obs9 = np.append(fmp_obs9,flask_mp_fh.variables['flask'][:x,9])\n",
    "            \n",
    "            fesm_obs0 = np.append(fesm_obs0,flask_esm_fh.variables['flask'][:x,0]) #Are 10 members. First check if it works with 1\n",
    "            fesm_obs1 = np.append(fesm_obs1,flask_esm_fh.variables['flask'][:x,1])\n",
    "            fesm_obs2 = np.append(fesm_obs2,flask_esm_fh.variables['flask'][:x,2])\n",
    "            fesm_obs3 = np.append(fesm_obs3,flask_esm_fh.variables['flask'][:x,3])\n",
    "            fesm_obs4 = np.append(fesm_obs4,flask_esm_fh.variables['flask'][:x,4])\n",
    "            fesm_obs5 = np.append(fesm_obs5,flask_esm_fh.variables['flask'][:x,5])\n",
    "            fesm_obs6 = np.append(fesm_obs6,flask_esm_fh.variables['flask'][:x,6])\n",
    "            fesm_obs7 = np.append(fesm_obs7,flask_esm_fh.variables['flask'][:x,7])\n",
    "            fesm_obs8 = np.append(fesm_obs8,flask_esm_fh.variables['flask'][:x,8])\n",
    "            fesm_obs9 = np.append(fesm_obs9,flask_esm_fh.variables['flask'][:x,9])\n",
    "            \n",
    "            flask_in_fh.close()\n",
    "            flask_mp_fh.close()\n",
    "            flask_esm_fh.close()\n",
    "            \n",
    "\n",
    "            #check if the shapes are similar, meaning that they have the same number of points\n",
    "            #print(np.shape(fin_obs),np.shape(fmp_obs0),np.shape(fesm_obs))\n",
    "            \n",
    "            #Code to transform the date components of the input file to a pandas series of timestamps\n",
    "            N = (len(fin_date))\n",
    "            base = datetime.datetime(1900, 1, 1)\n",
    "            time_intermediate = np.array([base + datetime.timedelta(hours=i) for i in xrange(N)])\n",
    "            for i in range(N):\n",
    "                dt = datetime.datetime(fin_date[i,0],fin_date[i,1],fin_date[i,2],fin_date[i,3],fin_date[i,4],fin_date[i,5])\n",
    "                time_intermediate[i] = pd.Timestamp(dt)\n",
    "            time = np.append(time,time_intermediate)    \n",
    "\n",
    "df = pd.DataFrame({'A_fin_obs' : fin_obs*1000000,\n",
    "                   'B_fmp_obs' : fmp_obs0*1000000,\n",
    "                   'C_fesm_obs': fesm_obs0*1000000,\n",
    "                   'D_alt'     : alt,\n",
    "                   'E_lat'     : lat,\n",
    "                   'F_lon'     : lon,\n",
    "                   'G_date'    : time},index=obs_num)\n",
    "\n",
    "ensemble = pd.DataFrame({'A_fin_obs' : fin_obs*1000000,\n",
    "                        'mp0' : fmp_obs0*1000000,\n",
    "                        'mp1' : fmp_obs1*1000000,\n",
    "                        'mp2' : fmp_obs2*1000000,\n",
    "                        'mp3' : fmp_obs3*1000000,\n",
    "                        'mp4' : fmp_obs4*1000000,\n",
    "                        'mp5' : fmp_obs5*1000000,\n",
    "                        'mp6' : fmp_obs6*1000000,\n",
    "                        'mp7' : fmp_obs7*1000000,\n",
    "                        'mp8' : fmp_obs8*1000000,\n",
    "                        'mp9' : fmp_obs9*1000000,\n",
    "                        'esm0' : fesm_obs0*1000000,\n",
    "                        'esm1' : fesm_obs1*1000000,\n",
    "                        'esm2' : fesm_obs2*1000000,\n",
    "                        'esm3' : fesm_obs3*1000000,\n",
    "                        'esm4' : fesm_obs4*1000000,\n",
    "                        'esm5' : fesm_obs5*1000000,\n",
    "                        'esm6' : fesm_obs6*1000000,\n",
    "                        'esm7' : fesm_obs7*1000000,\n",
    "                        'esm8' : fesm_obs8*1000000,\n",
    "                        'esm9' : fesm_obs9*1000000,\n",
    "                        'D_alt'     : alt,\n",
    "                        'E_lat'     : lat,\n",
    "                        'F_lon'     : lon,\n",
    "                        'G_date'    : time},index=obs_num)\n",
    "                  \n",
    "\n",
    "CBW = (df.E_lat>51) & (df.E_lat<52) & (df.F_lon>4) & (df.F_lon<5) #Cabauw in the Netherlands\n",
    "PAL = (df.E_lat>67) & (df.E_lat<68) & (df.F_lon>24) & (df.F_lon<25) #PALLAS in Finland\n",
    "LEF = (df.E_lat>45) & (df.E_lat<46) & (df.F_lon>-91) & (df.F_lon<-90) #Park Falls in Wisconsin (USA)\n",
    "JFJ = (df.E_lat>46) & (df.E_lat<47) & (df.F_lon>7) & (df.F_lon<8) #Jungfraujoch in Switserland\n",
    "\n",
    "CBW = (ensemble.E_lat>51) & (ensemble.E_lat<52) & (ensemble.F_lon>4) & (ensemble.F_lon<5) & (ensemble.G_date>'2009-07-01')#Cabauw in the Netherlands\n",
    "PAL = (ensemble.E_lat>67) & (ensemble.E_lat<68) & (ensemble.F_lon>24) & (ensemble.F_lon<25) #PALLAS in Finland\n",
    "mask = CBW\n",
    "\n",
    "ensemble = ensemble[mask]\n",
    "#print(fmp.duplicated('G_date'))\n",
    "#print(df[JFJ])\n",
    "sns.tsplot(ensemble.A_fin_obs, color='g',alpha=.2)\n",
    "sns.tsplot([ensemble.mp0,ensemble.mp1,ensemble.mp2,ensemble.mp3,ensemble.mp4,ensemble.mp5,\n",
    "            ensemble.mp6,ensemble.mp7,ensemble.mp8,ensemble.mp9],color='b',alpha=.2)\n",
    "sns.tsplot([ensemble.esm0,ensemble.esm1,ensemble.esm2,ensemble.esm3,ensemble.esm4,ensemble.esm5,\n",
    "            ensemble.esm6,ensemble.esm7,ensemble.esm8,ensemble.esm9],color='r',alpha=.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.head of           A_fin_obs   B_fmp_obs  C_fesm_obs  D_alt      E_lat    F_lon  \\\n",
      "24908.0  409.310014  420.544267  505.697331  990.0  47.801102  11.0245   \n",
      "\n",
      "                     G_date  \n",
      "24908.0 2009-01-07 11:55:00  >\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "#3. Altitude plots\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import datetime\n",
    "\n",
    "knmipath = '/nobackup/users/killaars/PhD_data/runs_may_2017'\n",
    "macbookpath = '/Users/killaars/PhD/test/'\n",
    "path = knmipath\n",
    "\n",
    "fin_obs = []\n",
    "time = []\n",
    "obs_num = []\n",
    "lat = []\n",
    "lon = []\n",
    "alt = []\n",
    "fmp_obs0 = []\n",
    "fesm_obs = []\n",
    "for root, dirs, files in os.walk(os.path.join(path,'sample_flasks')):\n",
    "    for file in sorted(files):\n",
    "        if file.startswith('sample_coordinates_'):\n",
    "            #print(file,file[19:])\n",
    "            #print 'flask_output_TM5_MP_'+file[19:]            \n",
    "            #print 'flask_output_ECE_'+file[19:]\n",
    "            TM5_MP_filename = 'flask_output_TM5_MP_'+file[19:]\n",
    "            ECE_filename = 'flask_output_ECE_'+file[19:]\n",
    "            \n",
    "            flask_in = os.path.join(path,'sample_flasks',file)\n",
    "            flask_mp = os.path.join(path,'TM5_offline',TM5_MP_filename)\n",
    "            flask_esm = os.path.join(path,'TM5_ESM',ECE_filename)\n",
    "\n",
    "            flask_in_fh = nc.Dataset(flask_in,mode='r')\n",
    "            flask_mp_fh = nc.Dataset(flask_mp,mode='r')\n",
    "            flask_esm_fh = nc.Dataset(flask_esm,mode='r')\n",
    "            \n",
    "            x = 40000000\n",
    "            fin_obs = np.append(fin_obs,flask_in_fh.variables['observed'][:x])\n",
    "            fin_date = flask_in_fh.variables['date_components'][:x]\n",
    "            obs_num = np.append(obs_num,flask_in_fh.variables['obs_num'][:x])\n",
    "            lat = np.append(lat,flask_in_fh.variables['latitude'][:x])\n",
    "            lon = np.append(lon,flask_in_fh.variables['longitude'][:x])\n",
    "            alt = np.append(alt,flask_in_fh.variables['altitude'][:x])\n",
    "            fmp_obs0 = np.append(fmp_obs0,flask_mp_fh.variables['flask'][:x,0]) #Are 10 members. First check if it works with 1\n",
    "            fesm_obs = np.append(fesm_obs,flask_esm_fh.variables['flask'][:x,0])\n",
    "            \n",
    "            flask_in_fh.close()\n",
    "            flask_mp_fh.close()\n",
    "            flask_esm_fh.close()\n",
    "\n",
    "            #check if the shapes are similar, meaning that they have the same number of points\n",
    "            #print(np.shape(fin_obs),np.shape(fmp_obs0),np.shape(fesm_obs))\n",
    "            \n",
    "            #Code to transform the date components of the input file to a pandas series of timestamps\n",
    "            N = (len(fin_date))\n",
    "            base = datetime.datetime(1900, 1, 1)\n",
    "            time_intermediate = np.array([base + datetime.timedelta(hours=i) for i in range(N)])\n",
    "            for i in range(N):\n",
    "                dt = datetime.datetime(fin_date[i,0],fin_date[i,1],fin_date[i,2],fin_date[i,3],fin_date[i,4],fin_date[i,5])\n",
    "                time_intermediate[i] = pd.Timestamp(dt)\n",
    "            time = np.append(time,time_intermediate)    \n",
    "\n",
    "df = pd.DataFrame({'A_fin_obs' : fin_obs*1000000,\n",
    "                   'B_fmp_obs' : fmp_obs0*1000000,\n",
    "                   'C_fesm_obs': fesm_obs*1000000,\n",
    "                   'D_alt'     : alt,\n",
    "                   'E_lat'     : lat,\n",
    "                   'F_lon'     : lon,\n",
    "                   'G_date'    : time},index=obs_num)\n",
    "\n",
    "\n",
    "CBW = (df.E_lat>51) & (df.E_lat<52) & (df.F_lon>4) & (df.F_lon<5) #Cabauw in the Netherlands\n",
    "PAL = (df.E_lat>67) & (df.E_lat<68) & (df.F_lon>24) & (df.F_lon<25) #PALLAS in Finland\n",
    "LEF = (df.E_lat>45) & (df.E_lat<46) & (df.F_lon>-91) & (df.F_lon<-90) #Park Falls in Wisconsin (USA)\n",
    "JFJ = (df.E_lat>46) & (df.E_lat<47) & (df.F_lon>7) & (df.F_lon<8) #Jungfraujoch in Switserland\n",
    "GLOB= (df.E_lat>-200) & (df.E_lat<200) & (df.F_lon>-200) & (df.F_lon<200) #Global mask to view all the data\n",
    "\n",
    "POL = (df.E_lat>80) & (df.E_lat<100) | (df.E_lat<-80) & (df.E_lat>=-100)   # Poles\n",
    "SUBPOL = (df.E_lat>60) & (df.E_lat<=80) | (df.E_lat<-60) & (df.E_lat>=-80) # Subpolair areas\n",
    "TEM = (df.E_lat>40) & (df.E_lat<=60) | (df.E_lat<-40) & (df.E_lat>=-60)    # Temperate zones\n",
    "SUBTRO = (df.E_lat>20) & (df.E_lat<=40) | (df.E_lat<-20) & (df.E_lat>=-40) # Subtropics\n",
    "TRO = (df.E_lat>-20) & (df.E_lat<=20)                                      # Tropics\n",
    "\n",
    "HIGH = (df.C_fesm_obs>500) \n",
    "print(df[HIGH].head)\n",
    "\n",
    "f, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1, 5, sharex=True, sharey=True, figsize=(20, 10))\n",
    "size = 2\n",
    "alpha=.3\n",
    "mask = POL\n",
    "\n",
    "# df['A_fin_obs'] = df['A_fin_obs']*1000000\n",
    "# df['B_fmp_obs'] = df['B_fmp_obs']*1000000\n",
    "# df['C_fesm_obs'] = df['C_fesm_obs']*1000000\n",
    "\n",
    "\n",
    "sys.exit()\n",
    "\n",
    "\n",
    "#Groups A_fin_obs by the altitude. The altitude is aggregated for each 50m and several statistics are done on each altitude value\n",
    "alt_fin_obs = df[mask]['A_fin_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "#standard error of the mean is calculated by dividing the standard deviation by the square root of the number of measurements\n",
    "alt_fin_obs['error']= alt_fin_obs['std']/np.sqrt(alt_fin_obs['count'])\n",
    "\n",
    "alt_fmp_obs = df[mask]['B_fmp_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fmp_obs['error']= alt_fmp_obs['std']/np.sqrt(alt_fmp_obs['count'])\n",
    "\n",
    "alt_fesm_obs = df[mask]['C_fesm_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fesm_obs['error']= alt_fesm_obs['std']/np.sqrt(alt_fesm_obs['count'])\n",
    "alt = np.arange(25,df[mask]['D_alt'].max()+25, 50)\n",
    "ax1.errorbar(alt_fin_obs['mean'], alt,xerr=alt_fin_obs['error'], fmt='o', color = 'g', alpha=alpha, ms=size,label='Observations')\n",
    "ax1.errorbar(alt_fmp_obs['mean'], alt,xerr=alt_fmp_obs['error'], fmt='o', color = 'b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax1.errorbar(alt_fesm_obs['mean'], alt,xerr=alt_fesm_obs['error'], fmt='o', color = 'r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "ax1.set_title(\"Poles\")\n",
    "#plt.xlim(380,420)\n",
    "plt.ylim(0,max(df.D_alt))\n",
    "\n",
    "mask = SUBPOL\n",
    "#Groups A_fin_obs by the altitude. The altitude is aggregated for each 50m and several statistics are done on each altitude value\n",
    "alt_fin_obs = df[mask]['A_fin_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "#standard error of the mean is calculated by dividing the standard deviation by the square root of the number of measurements\n",
    "alt_fin_obs['error']= alt_fin_obs['std']/np.sqrt(alt_fin_obs['count'])\n",
    "\n",
    "alt_fmp_obs = df[mask]['B_fmp_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fmp_obs['error']= alt_fmp_obs['std']/np.sqrt(alt_fmp_obs['count'])\n",
    "\n",
    "alt_fesm_obs = df[mask]['C_fesm_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fesm_obs['error']= alt_fesm_obs['std']/np.sqrt(alt_fesm_obs['count'])\n",
    "alt = np.arange(25,df[mask]['D_alt'].max()+25, 50)\n",
    "ax2.errorbar(alt_fin_obs['mean'], alt,xerr=alt_fin_obs['error'], fmt='o', color = 'g', alpha=alpha, ms=size,label='Observations')\n",
    "ax2.errorbar(alt_fmp_obs['mean'], alt,xerr=alt_fmp_obs['error'], fmt='o', color = 'b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax2.errorbar(alt_fesm_obs['mean'], alt,xerr=alt_fesm_obs['error'], fmt='o', color = 'r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "ax2.set_title(\"Sub Polair\")\n",
    "mask = TEM\n",
    "#Groups A_fin_obs by the altitude. The altitude is aggregated for each 50m and several statistics are done on each altitude value\n",
    "alt_fin_obs = df[mask]['A_fin_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "#standard error of the mean is calculated by dividing the standard deviation by the square root of the number of measurements\n",
    "alt_fin_obs['error']= alt_fin_obs['std']/np.sqrt(alt_fin_obs['count'])\n",
    "\n",
    "alt_fmp_obs = df[mask]['B_fmp_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fmp_obs['error']= alt_fmp_obs['std']/np.sqrt(alt_fmp_obs['count'])\n",
    "\n",
    "alt_fesm_obs = df[mask]['C_fesm_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fesm_obs['error']= alt_fesm_obs['std']/np.sqrt(alt_fesm_obs['count'])\n",
    "alt = np.arange(25,df[mask]['D_alt'].max()+25, 50)\n",
    "ax3.errorbar(alt_fin_obs['mean'], alt,xerr=alt_fin_obs['error'], fmt='o', color = 'g', alpha=alpha, ms=size,label='Observations')\n",
    "ax3.errorbar(alt_fmp_obs['mean'], alt,xerr=alt_fmp_obs['error'], fmt='o', color = 'b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax3.errorbar(alt_fesm_obs['mean'], alt,xerr=alt_fesm_obs['error'], fmt='o', color = 'r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "ax3.set_title(\"Temperate\")\n",
    "mask = SUBTRO\n",
    "#Groups A_fin_obs by the altitude. The altitude is aggregated for each 50m and several statistics are done on each altitude value\n",
    "alt_fin_obs = df[mask]['A_fin_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "#standard error of the mean is calculated by dividing the standard deviation by the square root of the number of measurements\n",
    "alt_fin_obs['error']= alt_fin_obs['std']/np.sqrt(alt_fin_obs['count'])\n",
    "\n",
    "alt_fmp_obs = df[mask]['B_fmp_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fmp_obs['error']= alt_fmp_obs['std']/np.sqrt(alt_fmp_obs['count'])\n",
    "\n",
    "alt_fesm_obs = df[mask]['C_fesm_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fesm_obs['error']= alt_fesm_obs['std']/np.sqrt(alt_fesm_obs['count'])\n",
    "alt = np.arange(25,df[mask]['D_alt'].max()+25, 50)\n",
    "ax4.errorbar(alt_fin_obs['mean'], alt,xerr=alt_fin_obs['error'], fmt='o', color = 'g', alpha=alpha, ms=size,label='Observations')\n",
    "ax4.errorbar(alt_fmp_obs['mean'], alt,xerr=alt_fmp_obs['error'], fmt='o', color = 'b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax4.errorbar(alt_fesm_obs['mean'], alt,xerr=alt_fesm_obs['error'], fmt='o', color = 'r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "ax4.set_title(\"Subtropics\")\n",
    "mask = TRO\n",
    "#Groups A_fin_obs by the altitude. The altitude is aggregated for each 50m and several statistics are done on each altitude value\n",
    "alt_fin_obs = df[mask]['A_fin_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "#standard error of the mean is calculated by dividing the standard deviation by the square root of the number of measurements\n",
    "alt_fin_obs['error']= alt_fin_obs['std']/np.sqrt(alt_fin_obs['count'])\n",
    "\n",
    "alt_fmp_obs = df[mask]['B_fmp_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fmp_obs['error']= alt_fmp_obs['std']/np.sqrt(alt_fmp_obs['count'])\n",
    "\n",
    "alt_fesm_obs = df[mask]['C_fesm_obs'].groupby(pd.cut(df[mask]['D_alt'], np.arange(0, df[mask]['D_alt'].max()+50, 50))).agg({'mean':np.mean,\n",
    "                                                                                                 'count':\"count\",\n",
    "                                                                                                 'std':np.std})\n",
    "alt_fesm_obs['error']= alt_fesm_obs['std']/np.sqrt(alt_fesm_obs['count'])\n",
    "alt = np.arange(25,df[mask]['D_alt'].max()+25, 50)\n",
    "ax5.errorbar(alt_fin_obs['mean'], alt,xerr=alt_fin_obs['error'], fmt='o', color = 'g', alpha=alpha, ms=size,label='Observations')\n",
    "ax5.errorbar(alt_fmp_obs['mean'], alt,xerr=alt_fmp_obs['error'], fmt='o', color = 'b', alpha=alpha, ms=size, label='TM5-Offline')\n",
    "ax5.errorbar(alt_fesm_obs['mean'], alt,xerr=alt_fesm_obs['error'], fmt='o', color = 'r', alpha=alpha, ms=size, label='TM5-ESM')\n",
    "ax5.set_title(\"Tropics\")\n",
    "\n",
    "ax1.set(ylabel='Altitude (m)')\n",
    "ax3.set(xlabel='CO2 concentration (ppm)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4. latitude heatmap\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "knmipath = '/nobackup/users/killaars/PhD_data/runs_may_2017'\n",
    "macbookpath = '/Users/killaars/PhD/test/'\n",
    "path = knmipath\n",
    "\n",
    "fin_obs = []\n",
    "time = []\n",
    "obs_num = []\n",
    "lat = []\n",
    "lon = []\n",
    "alt = []\n",
    "fmp_obs0 = []\n",
    "fesm_obs = []\n",
    "for root, dirs, files in os.walk(os.path.join(path,'sample_flasks')):\n",
    "    for file in sorted(files):\n",
    "        if file.startswith('sample_coordinates_'):\n",
    "            #print(file,file[19:])\n",
    "            #print 'flask_output_TM5_MP_'+file[19:]            \n",
    "            #print 'flask_output_ECE_'+file[19:]\n",
    "            TM5_MP_filename = 'flask_output_TM5_MP_'+file[19:]\n",
    "            ECE_filename = 'flask_output_ECE_'+file[19:]\n",
    "            \n",
    "            flask_in = os.path.join(path,'sample_flasks',file)\n",
    "            flask_mp = os.path.join(path,'TM5_offline',TM5_MP_filename)\n",
    "            flask_esm = os.path.join(path,'TM5_ESM',ECE_filename)\n",
    "\n",
    "            flask_in_fh = nc.Dataset(flask_in,mode='r')\n",
    "            flask_mp_fh = nc.Dataset(flask_mp,mode='r')\n",
    "            flask_esm_fh = nc.Dataset(flask_esm,mode='r')\n",
    "            \n",
    "            x = 40000000\n",
    "            fin_obs = np.append(fin_obs,flask_in_fh.variables['observed'][:x])\n",
    "            fin_date = flask_in_fh.variables['date_components'][:x]\n",
    "            obs_num = np.append(obs_num,flask_in_fh.variables['obs_num'][:x])\n",
    "            lat = np.append(lat,flask_in_fh.variables['latitude'][:x])\n",
    "            lon = np.append(lon,flask_in_fh.variables['longitude'][:x])\n",
    "            alt = np.append(alt,flask_in_fh.variables['altitude'][:x])\n",
    "            fmp_obs0 = np.append(fmp_obs0,flask_mp_fh.variables['flask'][:x,0]) #Are 10 members. First check if it works with 1\n",
    "            fesm_obs = np.append(fesm_obs,flask_esm_fh.variables['flask'][:x,0])\n",
    "            \n",
    "            flask_in_fh.close()\n",
    "            flask_mp_fh.close()\n",
    "            flask_esm_fh.close()\n",
    "\n",
    "            #check if the shapes are similar, meaning that they have the same number of points\n",
    "            #print(np.shape(fin_obs),np.shape(fmp_obs0),np.shape(fesm_obs))\n",
    "            \n",
    "            #Code to transform the date components of the input file to a pandas series of timestamps\n",
    "            N = (len(fin_date))\n",
    "            base = datetime.datetime(1900, 1, 1)\n",
    "            time_intermediate = np.array([base + datetime.timedelta(hours=i) for i in range(N)])\n",
    "            for i in range(N):\n",
    "                dt = datetime.datetime(fin_date[i,0],fin_date[i,1],fin_date[i,2],fin_date[i,3],fin_date[i,4],fin_date[i,5])\n",
    "                time_intermediate[i] = pd.Timestamp(dt)\n",
    "            time = np.append(time,time_intermediate)    \n",
    "\n",
    "df = pd.DataFrame({'A_fin_obs' : fin_obs*1000000,\n",
    "                   'B_fmp_obs' : fmp_obs0*1000000,\n",
    "                   'C_fesm_obs': fesm_obs*1000000,\n",
    "                   'D_alt'     : alt,\n",
    "                   'E_lat'     : lat,\n",
    "                   'F_lon'     : lon,\n",
    "                   'G_date'    : time},index=obs_num)\n",
    "\n",
    "GLOB= (df.E_lat>-200) & (df.E_lat<200) & (df.F_lon>-200) & (df.F_lon<200) #Global mask to view all the data\n",
    "mask=GLOB\n",
    "\n",
    "# lat_fin_obs = df[mask]['A_fin_obs'].groupby([pd.cut(df[mask]['E_lat'],np.arange(-90,100,10)),pd.cut(df[mask]['D_alt'],np.arange(0,13000,1000))]).agg({'mean':np.mean,\n",
    "#                                                                                                  'count':\"count\",\n",
    "#                                                                                                  'std':np.std})\n",
    "# Calculate the mean of all the values that fit in the numpy array boxes and use the unstack function to get rid of the multi-index dataframe\n",
    "lat_fin_obs_mean = df[mask]['A_fin_obs'].groupby([pd.cut(df[mask]['D_alt'],np.arange(0,14000,1000)),\n",
    "                                                  pd.cut(df[mask]['E_lat'],np.arange(-90,100,20))]).agg({'mean':np.mean}).unstack()\n",
    "lat_fmp_obs_mean = df[mask]['B_fmp_obs'].groupby([pd.cut(df[mask]['D_alt'],np.arange(0,14000,1000)),\n",
    "                                                  pd.cut(df[mask]['E_lat'],np.arange(-90,100,20))]).agg({'mean':np.mean}).unstack()\n",
    "lat_fesm_obs_mean = df[mask]['C_fesm_obs'].groupby([pd.cut(df[mask]['D_alt'],np.arange(0,14000,1000)),\n",
    "                                                    pd.cut(df[mask]['E_lat'],np.arange(-90,100,20))]).agg({'mean':np.mean}).unstack()\n",
    "\n",
    "# Do the same for the min and max, subtract them and unstack the resulting difference column.\n",
    "lat_fin_obs_diff = df[mask]['A_fin_obs'].groupby([pd.cut(df[mask]['D_alt'],np.arange(0,14000,1000)),\n",
    "                                                  pd.cut(df[mask]['E_lat'],np.arange(-90,100,20))]).agg({'max':np.max,'min':np.min})\n",
    "lat_fin_obs_diff['diff']=lat_fin_obs_diff['max']-lat_fin_obs_diff['min']\n",
    "lat_fin_obs_diff = lat_fin_obs_diff['diff'].unstack()\n",
    "\n",
    "# invert the altitude axis\n",
    "lat_fin_obs_mean = lat_fin_obs_mean.reindex(index=lat_fin_obs_mean.index[::-1])\n",
    "lat_fmp_obs_mean = lat_fmp_obs_mean.reindex(index=lat_fmp_obs_mean.index[::-1])\n",
    "lat_fesm_obs_mean = lat_fesm_obs_mean.reindex(index=lat_fesm_obs_mean.index[::-1])\n",
    "\n",
    "lat_fin_obs_diff = lat_fin_obs_diff.reindex(index=lat_fin_obs_diff.index[::-1])\n",
    "\n",
    "alt_index = np.arange(12500,-500,-1000)\n",
    "lat_index = np.arange(-80,90,20)\n",
    "\n",
    "f, (ax1) = plt.subplots(1, 1)\n",
    "ax1 = sns.heatmap(lat_fin_obs_mean,xticklabels=lat_index,yticklabels=alt_index, linewidths=.5, cmap=\"YlGnBu\")    \n",
    "ax1.set(xlabel='Latitude', ylabel='Altitude (m)',title='Observed CO2 concentrations in ppm')\n",
    "for item in (ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(8)\n",
    "plt.show()\n",
    "# ax2 = sns.heatmap(lat_fmp_obs-lat_fin_obs,xticklabels=lat_index,yticklabels=alt_index, linewidths=.5, cmap=\"YlGnBu\")    \n",
    "# ax2.set(xlabel='Latitude', ylabel='Altitude (m)',title='TM5-Offline CO2 concentrations in ppm')\n",
    "    \n",
    "# ax3 = sns.heatmap(lat_fesm_obs-lat_fin_obs,xticklabels=lat_index,yticklabels=alt_index, linewidths=.5, cmap=\"YlGnBu\")    \n",
    "# ax3.set(xlabel='Latitude', ylabel='Altitude (m)',title='TM5-ECE CO2 concentrations in ppm')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5. amplitude - latitude plot\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "knmipath = '/nobackup/users/killaars/PhD_data/runs_may_2017'\n",
    "macbookpath = '/Users/killaars/PhD/test/'\n",
    "path = knmipath\n",
    "\n",
    "fin_obs = []\n",
    "time = []\n",
    "obs_num = []\n",
    "lat = []\n",
    "lon = []\n",
    "alt = []\n",
    "fmp_obs0 = []\n",
    "fesm_obs = []\n",
    "for root, dirs, files in os.walk(os.path.join(path,'sample_flasks')):\n",
    "    for file in sorted(files):\n",
    "        if file.startswith('sample_coordinates_'):\n",
    "            #print(file,file[19:])\n",
    "            #print 'flask_output_TM5_MP_'+file[19:]            \n",
    "            #print 'flask_output_ECE_'+file[19:]\n",
    "            TM5_MP_filename = 'flask_output_TM5_MP_'+file[19:]\n",
    "            ECE_filename = 'flask_output_ECE_'+file[19:]\n",
    "            \n",
    "            flask_in = os.path.join(path,'sample_flasks',file)\n",
    "            flask_mp = os.path.join(path,'TM5_offline',TM5_MP_filename)\n",
    "            flask_esm = os.path.join(path,'TM5_ESM',ECE_filename)\n",
    "\n",
    "            flask_in_fh = nc.Dataset(flask_in,mode='r')\n",
    "            flask_mp_fh = nc.Dataset(flask_mp,mode='r')\n",
    "            flask_esm_fh = nc.Dataset(flask_esm,mode='r')\n",
    "            \n",
    "            x = 40000000\n",
    "            fin_obs = np.append(fin_obs,flask_in_fh.variables['observed'][:x])\n",
    "            fin_date = flask_in_fh.variables['date_components'][:x]\n",
    "            obs_num = np.append(obs_num,flask_in_fh.variables['obs_num'][:x])\n",
    "            lat = np.append(lat,flask_in_fh.variables['latitude'][:x])\n",
    "            lon = np.append(lon,flask_in_fh.variables['longitude'][:x])\n",
    "            alt = np.append(alt,flask_in_fh.variables['altitude'][:x])\n",
    "            fmp_obs0 = np.append(fmp_obs0,flask_mp_fh.variables['flask'][:x,0]) #Are 10 members. First check if it works with 1\n",
    "            fesm_obs = np.append(fesm_obs,flask_esm_fh.variables['flask'][:x,0])\n",
    "            \n",
    "            flask_in_fh.close()\n",
    "            flask_mp_fh.close()\n",
    "            flask_esm_fh.close()\n",
    "\n",
    "            #check if the shapes are similar, meaning that they have the same number of points\n",
    "            #print(np.shape(fin_obs),np.shape(fmp_obs0),np.shape(fesm_obs))\n",
    "            \n",
    "            #Code to transform the date components of the input file to a pandas series of timestamps\n",
    "            N = (len(fin_date))\n",
    "            base = datetime.datetime(1900, 1, 1)\n",
    "            time_intermediate = np.array([base + datetime.timedelta(hours=i) for i in range(N)])\n",
    "            for i in range(N):\n",
    "                dt = datetime.datetime(fin_date[i,0],fin_date[i,1],fin_date[i,2],fin_date[i,3],fin_date[i,4],fin_date[i,5])\n",
    "                time_intermediate[i] = pd.Timestamp(dt)\n",
    "            time = np.append(time,time_intermediate)    \n",
    "\n",
    "df = pd.DataFrame({'A_fin_obs' : fin_obs*1000000,\n",
    "                   'B_fmp_obs' : fmp_obs0*1000000,\n",
    "                   'C_fesm_obs': fesm_obs*1000000,\n",
    "                   'D_alt'     : alt,\n",
    "                   'E_lat'     : lat,\n",
    "                   'F_lon'     : lon,\n",
    "                   'G_date'    : time},index=obs_num)\n",
    "\n",
    "MLO = (df.E_lat>19) & (df.E_lat<20) & (df.F_lon>-155) & (df.F_lon<-154) #Mauna Loa, Hawai, US\n",
    "ALT = (df.E_lat>82) & (df.E_lat<83) & (df.F_lon>-63) & (df.F_lon<-62) #Alert, Alaska, US\n",
    "ASC = (df.E_lat>-8) & (df.E_lat<-7) & (df.F_lon>-15) & (df.F_lon<-14) #Ascencion Island (Middle Atlantic)\n",
    "AMT = (df.E_lat>45) & (df.E_lat<46) & (df.F_lon>-69) & (df.F_lon<-68) #Argyle, Maine, US\n",
    "CPT = (df.E_lat>-36) & (df.E_lat<-35) & (df.F_lon>18) & (df.F_lon<19) #Cape Town, South Africa\n",
    "GLOB= (df.E_lat>-200) & (df.E_lat<200) & (df.F_lon>-200) & (df.F_lon<200) #Global mask to view all the data\n",
    "masks = [MLO,ALT,ASC,AMT,CPT]\n",
    "\n",
    "#For stations: empty arrays, filled with the difference between the min and the max value at each location. The 'lat' array\n",
    "#consists of the latitude of the station\n",
    "fin_diff = []\n",
    "fmp_diff = []\n",
    "fesm_diff = []\n",
    "lat = []\n",
    "for mask in masks:\n",
    "    fin_diff=np.append(fin_diff,(df[mask]['A_fin_obs'].max()-df[mask]['A_fin_obs'].min()))\n",
    "    fmp_diff=np.append(fmp_diff,(df[mask]['B_fmp_obs'].max()-df[mask]['B_fmp_obs'].min()))\n",
    "    fesm_diff=np.append(fesm_diff,(df[mask]['C_fesm_obs'].max()-df[mask]['C_fesm_obs'].min()))\n",
    "    lat =  np.append(lat,df[mask]['E_lat'].max())\n",
    "\n",
    "                                                                                               \n",
    "# Calculate some statistics of all the values that fit in the numpy array boxes and calculate the amplitude of the timeseries\n",
    "lat_fin_obs = df['A_fin_obs'].groupby(pd.cut(df['E_lat'],np.arange(-90,95,5))).agg({'mean':np.mean,'min':np.min,'max':np.max})\n",
    "lat_fin_obs['diff'] = lat_fin_obs['max']-lat_fin_obs['min']\n",
    "\n",
    "lat_fmp_obs = df['B_fmp_obs'].groupby(pd.cut(df['E_lat'],np.arange(-90,95,5))).agg({'mean':np.mean,'min':np.min,'max':np.max})\n",
    "lat_fmp_obs['diff'] = lat_fmp_obs['max']-lat_fmp_obs['min']\n",
    "\n",
    "lat_fesm_obs = df['C_fesm_obs'].groupby(pd.cut(df['E_lat'],np.arange(-90,95,5))).agg({'mean':np.mean,'min':np.min,'max':np.max})\n",
    "lat_fesm_obs['diff'] = lat_fesm_obs['max']-lat_fesm_obs['min']\n",
    "\n",
    "f, (ax1,ax2) = plt.subplots(1, 2,sharey=True,sharex=True)\n",
    "plt.suptitle('Observed CO2 concentrations in ppm')\n",
    "size = 2\n",
    "alpha=.3\n",
    "\n",
    "ax1.scatter(lat,fin_diff,color='g', label='Observations')\n",
    "ax1.scatter(lat,fmp_diff,color='b', label='TM5-MP')\n",
    "ax1.scatter(lat,fesm_diff,color='r', label='TM5-ECE')\n",
    "ax2.scatter(np.arange(-90,90,5),lat_fin_obs['diff'],color='g', label='Observations')\n",
    "ax2.scatter(np.arange(-90,90,5),lat_fmp_obs['diff'],color='b', label='TM5-MP')\n",
    "ax2.scatter(np.arange(-90,90,5),lat_fesm_obs['diff'],color='r', label='TM5-ECE')\n",
    "ax1.set(xlabel='Latitude', ylabel='Concentration CO2 (ppm)')\n",
    "ax2.set(xlabel='Latitude')\n",
    "\n",
    "plt.ylim(np.min(lat_fin_obs['diff']),np.max(lat_fin_obs['diff']))\n",
    "plt.xlim(-90,90)\n",
    "plt.xticks(np.arange(-90, 90+30, 30))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
